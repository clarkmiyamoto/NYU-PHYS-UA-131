%%% Document Formatting
\documentclass[12pt,fleqn]{article}
\usepackage[a4paper,
            bindingoffset=0.2in,
            left=0.75in,
            right=0.75in,
            top=0.8in,
            bottom=0.8in,
            footskip=.25in]{geometry}
\setlength\parindent{10pt} % No indent

%%% Imports
% Mathematics
\usepackage{amsmath} % Math formatting
\numberwithin{equation}{section} % Number equation per section
\DeclareMathOperator{\Tr}{Tr}


\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{proof}{Proof}
\newtheorem{lemma}{Lemma}
\newtheorem{fact}{Fact}
\newtheorem{example}{Example}

\usepackage{amsmath}
\usepackage{amsfonts} % Math fonts
\usepackage{amssymb} % Math symbols
\usepackage{mathtools} % Math etc.
\usepackage{slashed} % Dirac slash notation
\usepackage{cancel} % Cancels to zero
\usepackage{empheq}
\usepackage{breqn}

\newcommand{\expect}[1]{\mathbb{E}\left[#1\right]}


% Visualization
\usepackage{graphicx} % for including images
\graphicspath{ {} } % Path to graphics folder
\usepackage{tikz}



%%% Formating
\usepackage{hyperref} % Hyperlinks
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }
\urlstyle{same}

\usepackage{mdframed} % Framed Enviroments
\newmdenv[ 
  topline=false,
  bottomline=false,
  skipabove=\topsep,
  skipbelow=\topsep
]{sidework} % Side-work Environment

\newcounter{problem}
\NewDocumentEnvironment{problem}{o}{%
  \refstepcounter{problem}%
  \IfNoValueTF{#1}
    {\def\problem@title{Problem~\theproblem}}
    {\def\problem@title{Problem~\theproblem ~(#1)}}%
  \begin{mdframed}[
    linecolor=black,
    linewidth=0.5pt,
    backgroundcolor=blue!2.5,
    innertopmargin=0pt,
    innerbottommargin=10pt,
    innerleftmargin=10pt,
    innerrightmargin=10pt,
    frametitlefont=\bfseries,
    frametitle=\problem@title,
  ]
}{%
  \end{mdframed}
} % Practice problem environment



\usepackage{lipsum} % Lorem Ipsum example text




%%%%% ------------------ %%%%%
%%% Title
\title{E\&M I Recitation Notes}
\author{Clark Miyamoto (cm6627@nyu.edu)}
\date{Fall 2025}
\begin{document}

\maketitle



\tableofcontents

\section{Note to Reader}
Problems more relevant to this class have an asterisk $(*)$, the other problems are good for your progression as a physicist. I added a lot of problems because I feel more comfortable after I do the same problem a couple times, but most people don't need that much practice-- feel free to a problem or two and move on.

\newpage
\section{Week 1: Delta Functions}
You know how in Physics 101, everything was a point particle? Well in E\&M we want to build a theory which can talk about point particles (like a single electron), but also a distribution of particles (like a slab of charged metal). You can imagine if we define the point particle in a naive way, the mathematical computation will turn out wrong... This is where we introduce the \textbf{delta function}.
\begin{sidework}
	This will be a computational introduction, i.e. how we use and manipulate these functions. If you're more of a proper mathematician, I recommend looking at my friend \href{https://notes.panos.wiki/Analysis+Distributions}{Panos's notes (https://notes.panos.wiki)}. He has a very well written notes for mathematicians working on physics.
\end{sidework}
\subsection{Kronecker Delta (Discrete)}
As always, we start discrete and then promote it to be continuous.
\begin{definition}
	[Kronecker Delta]
	\begin{align}
		\delta_{ij} = \begin{cases}
			1 & \text{if } i = j\\
			0 & \text{otherwise}
		\end{cases}
	\end{align}
	where $i,j$ are taken to be integers. It is usually unit-less.
\end{definition}
While this notation looks scary, if we interpret the indices as the row/column of a matrix, we realize this is just the identity matrix.
\begin{align}
	\mathbb I & = \begin{pmatrix}
		1 & 0 & 0 & \\
		0 & 1 & 0 & ...\\
		0 & 0 & 1 & \\
	  	  & \vdots & & \ddots
	\end{pmatrix} \implies [\mathbb I]_{ij}  = \delta_{ij}
\end{align}
In physics, this scary feeling will come up a lot. You'll be faced with a weird expression with kronecker deltas, etc. but you'll just realize that it ends up being a regular-old matrix operation. 
\begin{problem}[Properties of Kronecker] There are a couple fundamental properties of Kronecker deltas. They're pretty easy, so it's your job to show them!
	\begin{enumerate}
		\item Symmetry: $\delta_{ij} = \delta_{ji}$
		\item Contraction: $\sum_j a_j \delta_{ij} = a_i$
		\item Dimension: $\sum_{i=1}^n \delta_{ii} = n$
	\end{enumerate}
\end{problem}
Now we can apply our properties to break-down an expression with Kronecker deltas.
\begin{sidework}
	\emph{Example:} Consider the expression $\sum_{i=1}^n \sum_{j=1}^n \delta_{ij} a_i b_j$. If we interpret $a_i$ ($b_i$) as being the $i$'th entry from vector $\vec a$ ($\vec b$). What fundamental vector operation is this expression?
\begin{align}
	\sum_{i=1}^n \sum_{j=1}^n \delta_{ij} a_i b_j & = \sum_{i=1}^n a_i b_i & \text{Contraction property} \\
	& = \vec a \cdot \vec b & \text{By definition of dot product}
\end{align}
Wow it's just a dot product. \\
\\
Another way to see this is to use the identity matrix fact.
\begin{align}
	\sum_{i=1}^n \sum_{j=1}^n \delta_{ij} a_i b_j = \vec a^T ~\mathbb I ~\vec b = \vec a \cdot \vec b
\end{align}
Going back to the first proof. We that Kronecker deltas allow us to evaluate sums, this is because it is zero when $i \neq j$, so the only remaining component is $i= j$.
\end{sidework}
To get you comfortable with this, here's a couple of practice problems.
\begin{problem}[Kroneckers are not scary!]
	Let $A$ be a matrix, where $A_{ij} \equiv [A]_{ij}$ are the $i,j$'th entries of the matrix. What are the following expressions in-terms of simple linear algebra operations.
	\begin{enumerate}
		\item $\sum_{ij} \delta_{ij} A_{ij}$ 
		\item $\sum_{k\ell} \delta_{jk} \delta_{i \ell} A_{\ell k}$
		\item $\sum_{k\ell} \frac{1}{2} (\delta_{ij} \delta_{j\ell} + \delta_{i \ell} \delta_{jk}) A_{k\ell} $
	\end{enumerate}
\end{problem}


\subsection{Dirac Delta (Continuous)}
\subsubsection{Definition and Properties}
\begin{definition}
	[Dirac Delta/Delta Function, Heuristic] The delta function $\delta(x)$ is defined by the properties
	\begin{align}
		\delta(x-x') & = \begin{cases}
			\infty & \text{if } x = x'\\
			0 & \text{otherwise}
		\end{cases}\\
		\text{s.t. } \int_{\mathbb R} \delta(x-x')d x  & = 1
	\end{align}
\end{definition}
What is particularly funky, is this is not a function! It is a \textbf{distribution}! For our purposes, this means \underline{delta functions are only defined when being integrated against "well-behaved" functions}. So if you ever see an equality between a delta functions, these are only defined when you integrate both sides of the equation.\\
\\
Let me say this again a little more formally
\begin{definition}[Dirac Delta / Delta Function, Less Heuristic] Let $\varphi$ be a arbitrary test function (infinitely differentiable function with compact support). For our purposes, this means $\varphi(x)$ has the following properties
\begin{itemize}
	\item For all $n \in \mathbb N$, the derivative is finite $\frac{d^n}{dx^n}\varphi(x) < \infty$ 
	\item It goes to zero "quick-enough" as $x \to \infty$ such that $\int_{-\infty}^\infty \varphi(x) dx < \infty$.
	\item The first two imply it is zero at the boundary: $\lim_{x\to \infty} \varphi(x) = \lim_{x \to -\infty} \varphi(x) = 0$
\end{itemize}
The delta function is defined as
\begin{align}
	\int \varphi(x) \delta(x) dx = \varphi(0)
\end{align}
for all $\varphi$ test function.
\end{definition}
\textbf{Properties:}
\begin{itemize}
	\item Units: $\delta(x)$ has units $[x]^{-1}$.
	\begin{sidework}
		\emph{Proof:} We can see this by inspecting the integral
		\begin{align}
			\int \delta(x) dx = 1
		\end{align}
		The measure $dx$ has units $[x]$, and the RHS has no units. Therefore $\delta(x)$ must have units $[x]^{-1}$. QED.
	\end{sidework}
	\item Scaling
		\begin{align}
			\delta(a x) = \frac{\delta(x)}{|a|}
		\end{align}
		\begin{sidework}
	Remember, when you see $"="$ equalities, this really mean 
	"these are equal when being integrated against an arbitrary test function $\varphi$".\\
	\\
	So when I write
	\begin{align}
		\delta(a x) \text{ "=" } \frac{\delta(x)}{|a|}
	\end{align}
	What I implicitly mean is
	\begin{align}
		\int \delta(a x) \varphi(x) dx = \int \frac{\delta(x)}{|a|} \varphi(x) dx, ~~\forall \varphi \in \text{Test Functions}
	\end{align} So now let's prove it!\\
	\\
	\emph{Proof:} Consider the LHS being integrated against an arbitrary test function. We'll find it becomes the RHS We'll have to do this twice, once with $a = |a| > 0$ and $a = -|a| < 0$. Let's do the positive case:
	\begin{align}
		\int_{-\infty}^\infty \delta (ax) \varphi (x) dx & = \int_{-\infty}^\infty \frac{\delta(x)}{a} \varphi(x/a) dx  & u\text{-sub}~ x \mapsto x/a\\
		& = \frac{1}{a} \varphi(0) & \text{By def: }\int \delta(x) g(x) dx = g(0)
	\end{align}
	So it effectively acts like $\delta(x)/a$. If you instead $u$-sub'ed $x\mapsto - x /|a|$, you'll have gotten $\varphi(0) / a$. Thus we've shown
	\begin{align}
		\int \delta(ax) \varphi(x) dx = \int \frac{\delta(x)}{|a|} \varphi(x) dx
	\end{align} QED.
\end{sidework}
	\item Symmetry: by consequence of scaling
		\begin{align}
			\delta(-x) = \delta(x)
		\end{align}
	\item Translation
		\begin{align}
			\int \varphi(x) \delta(x- x') = \varphi(x')
		\end{align} 
	\item Variational derivative:
	\begin{align}
		\frac{\delta}{\delta \varphi(x)} \varphi(y) = \delta(x-y)
	\end{align}
\end{itemize}



\begin{problem}[$\star$ Charge Distributions]
	Charge distributions $\rho(\mathbf r') \equiv \text{Total Charge } (C) / \text{Volume of Charge } (m^3)$ often have delta functions in them. Given some example systems, find their representation in terms of delta functions: 
	\begin{itemize}
		\item Point charge w/ total charge $Q$.
		\item Infinite charged line lying on $(x,y) = (0,0)$, with linear charge density $\lambda$ (has units $[C/m]$).
		\item Infinite 2D plane lying on $z=0$, with surface charge density $\sigma$ (has units $[C/m^2]$).
		\item Infinite cylinder with radius $R$, with surface charge $\sigma$.
		\item Spherical shell of radius $R$, with total charge $Q$. 
	\end{itemize}
	\emph{Discussion:} How would you check your answer is correct? Recall equalities of expressions with delta functions are only defined in-terms of integrals, what does this mean in-terms of the physical system?
\end{problem}

\subsubsection{Showing something is a delta function in disguise}
In lecture, Grier mentioned the divergence of the vector field $\mathbf F(\mathbf r) = \frac{\mathbf{\hat{r}}}{\mathbf r^2}$ was
\begin{align}
	\boxed{\nabla \cdot \left ( \frac{\mathbf{\hat{r}}}{\mathbf r^2}\right) = 4\pi ~\delta^{(3)} (\mathbf r - \mathbf r')}
\end{align}
where $\nabla$ is the gradient operator.\\
\\
If you naively plug n' chug, you'd find $\nabla \cdot \left ( \frac{\mathbf{\hat{r}}}{\mathbf r^2}\right) =^? 0$. This is an artifact of a coordinate singularity (like how can you differentiate at $r \to 0$, it's not continuous). \\
\\
Grier makes a physics argument using $\nabla \cdot \mathbf E =  \rho / \epsilon_0$ as to why these are related. Here I'll show a mathematical proof.
\\
\\
\emph{Proof:} Recall a delta function is defined inside an integral, so we'll integrate this against an arbitrary scalar test function $\varphi : \mathbb R^3 \to \mathbb R$, and show it behaves like a delta function.\\
\\
First we can integrate by parts by noting $\text{div}(\vec f g) = (\nabla \cdot \vec f) g + \vec f \nabla g$
\begin{align}
	\int \varphi(\mathbf r) \nabla \cdot \left( \frac{\mathbf{\hat{r}}}{\mathbf r^2} \right) d^3 r & = \underbrace{\int \nabla\cdot (\varphi(\mathbf r) \frac{\mathbf{\hat{r}}}{\mathbf r^2}) d^3r}_{\text{Term (1)}} - \underbrace{\int \nabla\varphi(\mathbf r) \cdot \frac{\mathbf{\hat{r}}}{\mathbf r^2} d^3r}_{\text{Term (2)}}
\end{align}


Term (1): Use the divergence theorem
\begin{align}
	\int_V \nabla\cdot \left(\varphi(\mathbf r) \frac{\mathbf{\hat{r}}}{\mathbf r^2} \right) d^3r & = \int_{\partial V} \frac{\varphi(\mathbf r)}{\mathbf r^2}  \mathbf{\hat r} \cdot d\mathbf S \\
	& = 0 & \varphi \text{ vanishes at infinity}
\end{align}
\begin{sidework}
	This was a heuristic equality. To be formal, you would want to show
	\begin{fact}
		Let $f : U \to \mathbb R^d$ be a vector field which is $C^1$-smooth, and continuous up to the boundary of the domain $\partial U$. Then $\int_V \text{div} (F) = 0$.\\
		\\
		If $U$ is unbounded, this still holds when the directional derivative $\partial_{\vec v} f$ is absolutely integrable $\int_U |\partial_{\vec v} f| < \infty$.
	\end{fact}
	Test functions, by definition, fit these assumptions. For discussion see \href{https://mathoverflow.net/questions/150283/a-special-case-of-the-divergence-theorem}{this StackExchange post}.
\end{sidework}

Term (2): Use spherical coordinates
\begin{align}
	\int \nabla\varphi(\mathbf r) \cdot \frac{\mathbf{\hat{r}}}{\mathbf r^2} d^3r & = \int \nabla \varphi(\mathbf r) \cdot \frac{\mathbf{\hat{r}}}{\mathbf r^2} ~r^2 dr   d \Omega \\
	&= 4\pi   \int_0^\infty \frac{\partial \varphi}{\partial r}  dr \\
	& = 4\pi \varphi(r) \Big|_{r=0}^\infty & \text{Fundamental Theorem of Calculus}\\
	&  = 4\pi ( \cancelto{0}{\varphi(\infty)} - \varphi(0)) & \varphi \text{ vanishes at infinity}\\
	& = -4\pi \varphi(0)
\end{align}
Putting this all together
\begin{align}
	\int \varphi(\mathbf r) \nabla \cdot \left( \frac{\mathbf{\hat{r}}}{\mathbf r^2} \right) d^3 r = 4\pi \varphi(0)
\end{align}
Remember, if it acts like a delta function, it is a delta function by definition. QED.\\
\\
In general, proofs of this nature have lots of by parts calculations.
\begin{problem}[Representations of Delta Functions] The delta function emits an infinite number of representations. These are some common ones. Prove that they're actually delta functions!
	\begin{itemize}
		\item 8Laplacian Representation:
		\begin{align}
			\delta^{(3)} (\mathbf r - \mathbf r') = - \frac{1}{4\pi} \nabla^2 \frac{1}{|\mathbf r - \mathbf r'|}
		\end{align}
		where $|\cdot |$ is the magnitude of a vector.
		\item $(\star)$ Fourier Representation (very important for quantum mechanics!)
		\begin{align}
			\delta(x) = \int_{\mathbb R} \frac{d k}{2\pi} ~ e^{i k x}
		\end{align}
		
		\item Gaussian Representation
		\begin{align}
			\delta(x) = \lim_{\epsilon \to 0^+}  \frac{1}{\epsilon \sqrt{2\pi}} \exp \left(-\frac{1}{2} \frac{x^2}{\epsilon^2} \right)
		\end{align}
	\end{itemize}
	A good question to ask yourself, how do these generalize when $x \in \mathbb R^d$?
\end{problem}

\newpage
\section{Week 2: }


\newpage
\section{Appendix}

\subsection{Review of Vector Calculus}
\subsubsection{Coordinates}
In this section, and probably for everything else in these notes, we'll assume we work with functions that have domain on $\mathbb R^3$.\\
\\
Consider a vector $\vec r \in \mathbb R^3$. We can also decompose it a complete basis $\{\mathbf{\hat x}, \mathbf{\hat y}, \mathbf{\hat z}\}$, where the $\mathbf{\hat v}$ (hat symbol) signifies it is a unit vector.
\begin{align}
	\vec r  = x \mathbf{\hat x} + y \mathbf{\hat y} + z \mathbf {\hat z}
\end{align}




\subsubsection{Change of Coordinates of Differential Operators}
In classical mechanics, you probably had to work with differential operators. For example: the gradient $\vec \nabla$, the laplacian $\nabla^2 \equiv \vec \nabla \cdot \vec \nabla$, etc. However these have expressions depending on your coordinate system.
\begin{align}
	\vec \nabla & = \frac{\partial}{\partial x} \mathbf{\hat x} + \frac{\partial}{\partial y} \mathbf{\hat y} + \frac{\partial}{\partial z} \mathbf{\hat z}
\end{align}


 You might have noticed that certain problems are more amendable 



\subsection{Helmholtz Theorem}
\begin{theorem}
	[Helmholtz Theorem] Consider a vector field $\mathbf F \in C^2(V)$ where the domain is bounded $V \subseteq \mathbb R^3$. Then $\mathbf F$ can be decomposed into a curl free component and divergence free component
	\begin{align}
		\mathbf F = - \nabla \Phi + \nabla \times \mathbf A,\\
		\Phi(\mathbf r)
	\end{align}
\end{theorem}






\subsection{Fourier Analysis}
If you're a STEM major, you have probably seen \href{https://www.youtube.com/watch?v=spUNpyF58BY}
{3Blue1Brown's video on Fourier Analysis} (if you haven't, you should watch it now!). Basically he visualizes how complex signals can be decomposed into pure-signals of sines and cosines. I'll try to introduce it again, but lay the notation \& computational workflow for accomplishing this.\\
\\
What we'll learn is that any piecewise-smooth function can be represented as a linear combination of $\sin$ and $\cos$
\begin{align}
	f(x) & = A_0 + \sum_{n=1}^\infty \left [ A_n \cos \left( \tfrac{2\pi n}{P} x \right) + B_n \sin (\tfrac{2\pi n}{P} x) \right]\\
	\text{s.t. } A_0 & = \frac{1}{P} \int_{P} f(a)~ da\\
	A_n & = \frac{2}{P} \int_P f(a) \cos \left( \tfrac{2\pi n}{P} a \right) ~da & (n \geq 1)\\
	B_n & = \frac{2}{P} \int_P f(x) \sin \left( \tfrac{2\pi n}{P} a \right) ~da & (n \geq 1)
\end{align}

\subsubsection{Fourier Series Expansion}



\subsubsection{Fourier Transform}

\subsubsection{Connection to Linear Independence / Basis}








































\end{document}